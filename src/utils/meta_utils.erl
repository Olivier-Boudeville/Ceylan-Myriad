% Copyright (C) 2014-2015 Olivier Boudeville
%
% This file is part of the Ceylan Erlang library.
%
% This library is free software: you can redistribute it and/or modify
% it under the terms of the GNU Lesser General Public License or
% the GNU General Public License, as they are published by the Free Software
% Foundation, either version 3 of these Licenses, or (at your option)
% any later version.
% You can also redistribute it and/or modify it under the terms of the
% Mozilla Public License, version 1.1 or later.
%
% This library is distributed in the hope that it will be useful,
% but WITHOUT ANY WARRANTY; without even the implied warranty of
% MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
% GNU Lesser General Public License and the GNU General Public License
% for more details.
%
% You should have received a copy of the GNU Lesser General Public
% License, of the GNU General Public License and of the Mozilla Public License
% along with this library.
% If not, see <http://www.gnu.org/licenses/> and
% <http://www.mozilla.org/MPL/>.
%
% Author: Olivier Boudeville (olivier.boudeville@esperide.com)
% Creation date: Friday, December 19, 2014




% Gathering of various convenient meta-related facilities, notably regarding
% metaprogramming and parse transforms.
%
% See meta_utils_test.erl for the corresponding test.
%
% Note that this module is a prerequisite of parse transforms, hence it must be
% bootstrapped *before* they are built, and cannot use them.
%
% So, to compile it, just go to the root of this layer and execute for example
% 'make all'.
%
-module(meta_utils).



% Implementation notes:

% Here are some resources to better understand parse transforms (PT, here):
%
% - generic information about PT: in http://www.erlang-factory.com/ :
% upload/presentations/521/yrashk_parse_transformations_sf12.pdf
%
% - Abstract Format: http://www.erlang.org/doc/apps/erts/absform.html (full spec
% of the AST format)
%
% - http://chlorophil.blogspot.fr/2007/04/erlang-macro-processor-v1-part-i.html
%   http://chlorophil.blogspot.fr/2007/04/atomiser-part-ii.html
%   http://chlorophil.blogspot.fr/2007/04/atomiser-part-iii.html
%   http://chlorophil.blogspot.fr/2007/04/atomiser-part-iv.html
%   http://chlorophil.blogspot.fr/2007/04/atomiser-part-v.html
%   http://chlorophil.blogspot.fr/2007/04/atomiser-part-vi.html
%   http://chlorophil.blogspot.fr/2007/04/atomiser-part-vii.html


% Standard modules of interest:
%
% - erl_scan ('The Erlang Token Scanner'): functions for tokenizing characters
% into Erlang tokens
%
% - epp ('An Erlang Code Preprocessor'): functions which are used by compile to
% preprocess macros and include files before the actual parsing
%
% - erl_parse ('The Erlang Parser'): basic Erlang parser
%
% - erl_eval ('The Erlang Meta Interpreter'): interpreter for Erlang
% expressions, in the abstract syntax
%
% - erl_pp ('The Erlang Pretty Printer'): to display abstract forms
%
% - erl_lint ('The Erlang Code Linter'): to check Erlang code for illegal
% syntax, bugs, unrecommended coding practices, etc.
%
% - compile ('The Erlang Compiler'): interface to the standard Erlang compiler

% Example of PT: http://www.erlang.org/doc/man/erl_id_trans.html


% Third-party libraries of interest:
%
% - https://github.com/uwiger/parse_trans
% - https://github.com/uwiger/toker


% Useful information:
%
% - how to convert source code into actual code: on
% http://stackoverflow.com/questions/,
% 2160660/how-to-compile-erlang-code-loaded-into-a-string


% Use -P to see the code generated by a parse-transform; ex: 'erlc -P' or in the
% shell as 'c( "X.erl", [ 'P' ] )".



% For function_info:
-include("meta_utils.hrl").


% For the file_info record:
-include_lib("kernel/include/file.hrl").



% Type-related section.


% Options specified to a parse transform at runtime, like report_warnings,
% beam,report_errors, {cwd,"X"}, {outdir,"Y"}, {i,"Z"}, {parse_transform,P},
% debug_info,warnings_as_errors, etc.
%
-type parse_transform_options() :: proplists:proplist().


% Line-related location in a source file:
-type file_loc() :: erl_scan:location().


% Line location in a source file:
-type line() :: erl_scan:line().


% Abstract form, part of an AST:
%
-type form() :: erl_parse:abstract_form().


% Abstract Syntax Tree, standard representation of parse trees for Erlang
% programs as Erlang terms. This representation is known as the abstract
% format.
%
% For more information: http://www.erlang.org/doc/apps/erts/absform.html
%
-type ast() :: erl_parse:abstract_form().


% The name of a (parse-level) attribute (ex: '-my_attribute( my_value ).').
%
-type attribute_name() :: atom().


% The value of a (parse-level) attribute (ex: '-my_attribute( my_value ).').
%
-type attribute_value() :: term().



% Parse-level attribute:
%
-type attribute() :: { attribute_name(), attribute_value() }.



% The name of a function:
%
-type function_name() :: basic_utils:function_name().


% Declaration of a function based on a name with an arity (unique function
% signature within a module):
%
-type function_id() :: { function_name(), arity() }.


% The form corresponding to the definition of a clause of a function, typically
% { clause, LINE, Rep(Ps), Rep(Gs), Rep(B) } for '( Ps ) when Gs -> B':
%
-type clause_def() :: ast().


% The full type definition (if any) of that function, as an abstract form;
% typically:
%
% { attribute, L, spec, { {foobar,Arity}, [{type,L,'fun', [{type,L,...
%
-type function_spec() :: ast().



-type function_info() :: #function_info{}.



% Describes the name of a type (without the number of the types it depends on,
% for polymorphic ones).
%
-type type_name() :: atom().


% Number of types a (possibly polymorphic) type depends on (possibly zero for
% plain types).
%
-type type_arity() :: basic_utils:count().


% The "most precise" description of a primitive, simple type (ex: 'boolean' and
% 'atom' coexist, 'number ' are not used), etc.
%
-type type_description() :: 'atom' | 'binary' | 'boolean' | 'float' | 'function'
						  | 'integer' | 'list' | 'pid' | 'port' | 'record'
						  | 'reference' | 'tuple'.


% Description of a type:
%
-type type() :: term().


% Type of functions to transform terms during a recursive traversal (see
% traverse_term/4).
%
% Note: apparently we cannot use the 'when' notation here (InputTerm ... when
% InputTerm :: term()).
%
-type term_transformer() :: fun( ( term(), basic_utils:user_data() ) ->
									   { term(), basic_utils:user_data() } ).




-type module_info() :: #module_info{}.


-export_type([ parse_transform_options/0, file_loc/0, line/0, ast/0, form/0,
			   attribute_name/0, attribute_value/0, attribute/0,
			   function_name/0, function_id/0,
			   clause_def/0, function_spec/0, function_info/0,
			   type_name/0, type_arity/0, type_description/0, type/0,
			   term_transformer/0,
			   module_info/0
			 ]).



% Parse-transform related functions:

-export([ init_module_info/0,
		  function_info_to_string/1, get_type_of/1, traverse_term/4,
		  term_to_form/1, variable_names_to_form/2,
		  form_to_ast/1, form_to_ast/2, term_to_ast/1, term_to_ast/2,
		  beam_to_ast/1, process_module_ast/1,
		  erl_to_ast/1,
		  check_module_info/1, module_info_to_string/1,
		  raise_error/1 ]).



% Returns a new, blank instance of the module_info record.
%
init_module_info() ->

	% No table pseudo-module available from meta_utils, as it cannot be
	% parse-transformed; only map_hashtable is available here, not the other
	% *_hashtable counterparts (once that meta_utils module is compiled, if it
	% relied on foo_hashtable, then the parse transform could not operate on any
	% module compiled before foo_hashtable):
	%
	#module_info{ functions=map_hashtable:new() }.



% Returns a textual description of the specified function information.
%
-spec function_info_to_string( function_info() ) -> text_utils:ustring().
function_info_to_string( #function_info{
		   name=Name,
		   arity=Arity,
		   definition=Clauses,
		   spec=Spec,
		   exported=Exported } ) ->

	ExportString = case Exported of

					   true ->
						   "exported";

					   false ->
						   "local"

	end,

	DefString = io_lib:format( "~B clause(s) defined", [ length( Clauses ) ] ),

	SpecString = case Spec of

					 undefined ->
						 "no type specification";

					 _ ->
						 "a type specification"

	end,

	io_lib:format( "~s/~B, ~s, with ~s and ~s",
				   [ Name, Arity, ExportString, DefString, SpecString ] ).



% Returns an atom describing, as precisely as possible, the type of the
% specified term.
%
% 'is_num', 'is_record', etc. not usable here.
%
-spec get_type_of( term() ) -> type_description().
get_type_of( Term ) when is_boolean( Term ) ->
	'boolean';

get_type_of( Term ) when is_atom( Term ) ->
	'atom';

get_type_of( Term ) when is_binary( Term ) ->
	'binary';

get_type_of( Term ) when is_float( Term ) ->
	'float';

get_type_of( Term ) when is_function( Term ) ->
	'function';

get_type_of( Term ) when is_integer( Term ) ->
	'integer';

get_type_of( Term ) when is_pid( Term ) ->
	'pid';

get_type_of( Term ) when is_list( Term ) ->
	'list';

get_type_of( Term ) when is_port( Term ) ->
	'port';

%get_type_of( Term ) when is_record( Term ) ->
%	'record';

get_type_of( Term ) when is_tuple( Term ) ->
	'tuple';

get_type_of( Term ) when is_reference( Term ) ->
	'reference'.




% Traverses specified term (possibly with nested subterms - the function will
% recurse in lists and tuples), calling specified transformer function on each
% instance of specified type, in order to replace that instance by the result of
% that function.
%
% Returns an updated term, with these replacements made.
%
% Ex: the input term could be T={ a, [ "foo", { c, [ 2.0, 45 ] } ] } and the
% function might replace, for example, floats by <<bar>>; then T'={ a, [ "foo",
% { c, [ <<bar>>, 45 ] } ] } would be returned.
%
% Note: the transformed terms are themselves recursively transformed, to ensure
% nesting is managed. Of course this implies that the term transform should not
% result in iterating the transformation infinitely.
%
% As a result it may appear that a term of the targeted type is transformed
% almost systematically twice: it is first transformed as such, and the result
% is transformed in turn. If the transformed term is the same as the original
% one, then that content will be shown as analysed twice.
%
-spec traverse_term( term(), type_description(), term_transformer(),
			 basic_utils:user_data() ) -> { term(), basic_utils:user_data() }.

% Here the term is a list and this is the type we want to intercept:
traverse_term( TargetTerm, _TypeDescription=list, TermTransformer, UserData )
  when is_list( TargetTerm ) ->

	{ TransformedTerm, NewUserData } = TermTransformer( TargetTerm, UserData ),

	traverse_transformed_term( TransformedTerm, _TypeDescription=list,
							   TermTransformer, NewUserData );


% Here the term is a list and we are not interested in them:
traverse_term( TargetTerm, TypeDescription, TermTransformer, UserData )
  when is_list( TargetTerm ) ->

	traverse_list( TargetTerm, TypeDescription, TermTransformer, UserData );


% Here the term is a tuple (or a record...), and we want to intercept them:
traverse_term( TargetTerm, TypeDescription, TermTransformer, UserData )
  when is_tuple( TargetTerm )
	andalso ( TypeDescription =:= tuple orelse TypeDescription =:= record ) ->

	{ TransformedTerm, NewUserData } = TermTransformer( TargetTerm, UserData ),

	traverse_transformed_term( TransformedTerm, TypeDescription,
							   TermTransformer, NewUserData );


% Here the term is a tuple (or a record...), and we are not interested in them:
traverse_term( TargetTerm, TypeDescription, TermTransformer, UserData )
  when is_tuple( TargetTerm ) ->

	traverse_tuple( TargetTerm, TypeDescription, TermTransformer, UserData );


% Base case (current term is not a binding structure, it is a leaf of the
% underlying syntax tree):
%
traverse_term( TargetTerm, TypeDescription, TermTransformer, UserData ) ->

	case get_type_of( TargetTerm ) of

		TypeDescription ->
			TermTransformer( TargetTerm, UserData );

		_ ->
			% Unchanged:
			{ TargetTerm, UserData }

	end.



% Helper to traverse a list.
%
traverse_list( TargetList, TypeDescription, TermTransformer, UserData ) ->

	{ NewList, NewUserData } = lists:foldl( fun( Elem, { AccList, AccData } ) ->

			{ TransformedElem, UpdatedData } = traverse_term( Elem,
							TypeDescription, TermTransformer, AccData ),

			% New accumulator, produces a reversed element list:
			{ [ TransformedElem | AccList ], UpdatedData }

											end,

											_Acc0={ _Elems=[], UserData },

											TargetList ),

	{ lists:reverse( NewList ), NewUserData }.



% Helper to traverse a tuple.
%
traverse_tuple( TargetTuple, TypeDescription, TermTransformer, UserData ) ->

	% We do exactly as with lists:
	TermAsList = tuple_to_list( TargetTuple ),

	{ NewList, NewUserData } = traverse_list( TermAsList, TypeDescription,
											  TermTransformer, UserData ),

	{ list_to_tuple( NewList ), NewUserData }.



% Helper to traverse a transformed term (ex: if looking for a { user_id, String
% } pair, we must recurse in nested tuples like: { 3, { user_id, "Hello" }, 1 }.
%
traverse_transformed_term( TargetTerm, TypeDescription, TermTransformer,
						   UserData ) ->

	case TermTransformer( TargetTerm, UserData ) of

		{ TransformedTerm, NewUserData } when is_list( TransformedTerm ) ->
			traverse_list( TransformedTerm, TypeDescription, TermTransformer,
						   NewUserData );

		{ TransformedTerm, NewUserData } when is_tuple( TransformedTerm ) ->
			traverse_tuple( TransformedTerm, TypeDescription, TermTransformer,
						   NewUserData );

		% { ImmediateTerm, NewUserData } ->
		Other ->
			Other

	end.




% Section to generate AST.


% Converts the specified Erlang term (ex: the float '42.0') into a corresponding
% form (ex: '{ float, _Line=0, 42.0 }').
%
-spec term_to_form( term() ) -> ast().
term_to_form( Term ) ->

	case erl_syntax:abstract( Term ) of

		badarg ->
			throw( { term_abstraction_failed, Term } );

		SyntaxTree ->

			% Could be used with erl_syntax:is_tree/1:
			% case erl_syntax:revert( SyntaxTree ) of...
			erl_syntax:revert( SyntaxTree )

	end.



% Converts a list of names of variables into the corresponding form.
%
% Ex: variable_names_to_form( [ "V1", "Alpha", "A" ], _Line=0 ) = [ {cons,0,
% {var,0,'V1'}, {cons,0,{var,0,'Alpha'}, {cons,0,{var,0,'A'}, {nil,0} } } } ]
%
-spec variable_names_to_form( [ string() ], line() ) -> form().
variable_names_to_form( VariableNames, Line ) ->

	% Could be done directly recursively by incrementally 'consing' reversed
	% list.

	NameListString = "[ " ++ text_utils:join( ", ",  VariableNames ) ++ " ].",

	term_to_ast( NameListString, Line ).





% Converts the specified source code of a form (i.e., a string) into its
% corresponding abstract form (assuming being in line #1).
%
% Ex: form_to_ast( "f() -> hello_world." ) returns
%   { function, 1, f, 0, [ { clause, 1, [], [], [ {atom,1,hello_world} ] } ] }
%
-spec form_to_ast( string() ) -> ast().
form_to_ast( FormString ) ->
	form_to_ast( FormString, _Loc=1 ).


% Converts the specified source code of a form (i.e., a string) into its
% corresponding abstract form.
%
% Ex: form_to_ast( "f() -> hello_world.", 42 ) returns
%   { function, 1, f, 0, [ { clause, 42, [], [], [ {atom,1,hello_world} ] } ] }
%
-spec form_to_ast( string(), file_loc() ) -> ast().
form_to_ast( FormString, Location ) ->

	% First get Erlang tokens from that string:
	Tokens = case erl_scan:string( FormString, Location ) of

		% Ex: [{atom,1,f},{'(',1},{')',1},{'->',1},{atom,1,hello_world},{dot,1}]
		{ ok, Toks, _EndLocation } ->
			%io:format( "Tokens: ~p~n", [ Toks ] ),
			Toks;

		ErrorTok ->
			throw( { form_tokenizing_error, FormString, ErrorTok } )

	end,

	% Tokens to erl_parse trees:

	case erl_parse:parse_form( Tokens ) of

			  { ok, ParseTree } ->
				  ParseTree;

			  ErrorPar ->
				  throw( { form_parsing_error, FormString, ErrorPar } )

	end.



% Converts the specified source code of a term (i.e., a string) into its
% corresponding abstract form (assuming being in line #1).
%
% Ex: term_to_ast( "[ { a, 1 }, foobar ]" ) returns
%   [ { cons, 1, { tuple, 1, [ {atom,1,a}, {integer,1,1} ] },
%     { cons, 1, {atom,1,foobar}, {nil,1} } } ]
%
-spec term_to_ast( string() ) -> ast().
term_to_ast( TermString ) ->
	term_to_ast( TermString, _Loc=1 ).



% Converts the specified source code of a term (i.e., a string) into its
% corresponding abstract form.
%
% Ex: term_to_ast( "[ { a, 1 }, foobar ]", _Loc=42 ) returns
%   [ { cons, 42, { tuple, 42, [ {atom,42,a}, {integer,42,1} ] },
%     { cons, 42, {atom,42,foobar}, {nil,42} } } ]
%
term_to_ast( TermString, Location ) ->

	% First get Erlang tokens from that string:
	Tokens = case erl_scan:string( TermString, Location ) of

		% Ex: [ {'[',42}, {'{',42}, {atom,42,a}, {',',42}, {integer,42,1},
		% {'}',42}, {',',42}, {atom,42,foobar}, {']',42} ]
		{ ok, Toks, _EndLocation } ->
			%io:format( "Tokens: ~p~n", [ Toks ] ),
			Toks;

		ErrorTok ->
			throw( { term_tokenizing_error, TermString, ErrorTok } )

	end,

	% Tokens to erl_parse trees:

	case erl_parse:parse_exprs( Tokens ) of

			  { ok, ParseTree } ->
				  ParseTree;

			  ErrorPar ->
				  throw( { term_parsing_error, TermString, ErrorPar } )

	end.



% Reads the specified BEAM file (expected to be compiled with debug information)
% and returns the corresponding AST.
%
% Note that the filename must be a relative or absolute path pointing directly
% to the BEAM file (it is not searched through the code path).
%
-spec beam_to_ast( file:filename() ) -> ast().
beam_to_ast( BeamFilename ) ->

	% We do not use functions from other Common modules here (ex: file_utils) as
	% they are not expected to be built yet (they will be built with the common
	% parse transform afterwards).
	%
	case file:read_link_info( BeamFilename ) of

		{ ok, FileInfo } ->
			#file_info{ type=regular } = FileInfo,
			ok;

		{ error, eloop } ->
			% Probably a recursive symlink:
			throw( { too_many_symlink_levels, BeamFilename } );

		{ error, enoent } ->
			throw( { non_existing_beam_file, BeamFilename } )

	end,

	% We could basically list all chunks, but we are only interested here in the
	% abstract code:
	%

	% Everything:
	%Chunks = [ abstract_code, attributes, compile_info, exports,
	%		   labeled_exports, imports, indexed_imports, locals,
	%		   labeled_locals, atoms ],

	% Just the code AST:
	Chunks = [ abstract_code ],

	% Everything but the code AST:
	%Chunks = [ attributes, compile_info, exports,
	%		   labeled_exports, imports, indexed_imports, locals,
	%		   labeled_locals, atoms ],

	%Options = [ allow_missing_chunks ],
	Options=[],

	case beam_lib:chunks( BeamFilename, Chunks, Options ) of

		{ ok, { _Module, [ { abstract_code, { _RawAbstractV1,
											  AbstractCode } } ] } } ->
			%io:format( "Module = ~p.~n", [ Module ] ),
			AbstractCode;

		{ error, beam_lib, Reason } ->
			throw( { beam_reading_failed, Reason } )

	end.



% Processes the specified AST relative to a whole module, and returns the
% corresponding information gathered.
%
-spec process_module_ast( ast() ) -> module_info().
process_module_ast( AST ) ->

	%io:format( "Processing following AST:~n~p~n", [ AST ] ),
	io:format( "Processing AST:~n" ),

	InitModuleInfo = init_module_info(),

	ModuleInfo = process_ast( AST, InitModuleInfo ),

	% Uncomment with care: ultimately depends on non-bootstrapped modules (like
	% text_utils):
	%
	%io:format( "Resulting module information:~n~s~n",
	%		   [ module_info_to_string( ModuleInfo ) ] ),

	%check_module_info( ModuleInfo ),

	ModuleInfo.




% Here all relevant parts of the specified AST are matched in turn:


% Module section:

% Any lacking, invalid or duplicated module declaration will be caught by the
% compiler anyway:
%
-spec process_ast( [ ast() ], module_info() ) -> module_info().
process_ast( _AST=[ F={ attribute, _Line, module, ModuleName } | T ],
			 W=#module_info{ module=undefined, module_def=undefined } ) ->

	%io:format( " - module declaration for ~s~n", [ ModuleName ] ),

	% When processing X.beam, we could remove the lines like:
	% {attribute,37,file,{"X.erl",37}

	process_ast( T, W#module_info{ module=ModuleName, module_def=F } );


% Include section:
%
process_ast( _AST=[ F={ attribute, _Line, file, { Filename, _N } } | T ],
			 W=#module_info{ includes=Inc, include_defs=IncDefs } ) ->

	%io:format( " - file declaration with ~s~n", [ Filename ] ),

	% We used to normalise paths, however then 'file_utils' would have to be
	% bootstrapped as well, which does not seem desirable.

	%NormFilename = file_utils:normalise_path( Filename ),
	NormFilename = Filename,

	% Avoids duplicates (in 'includes' only):
	%
	NewFilenames = case lists:member( NormFilename, Inc ) of

					   true ->
						   Inc;

					   false ->
						   [ NormFilename | Inc ]

	end,

	process_ast( T, W#module_info{ includes=NewFilenames,
								   include_defs=[ F | IncDefs ] } );



% Type definition section:
%
process_ast( _AST=[ F={ attribute, _Line, type,
						{ TypeName, TypeDef, _SubTypeList } } | T ],
			 W=#module_info{ type_definitions=TypeDefs,
							 type_definition_defs=TypeDefsDefs } ) ->

	%io:format( " - type declaration for ~p: ~p~n", [ TypeName, F ] ),

	process_ast( T, W#module_info{
				   type_definitions=[ { TypeName, TypeDef } | TypeDefs ],
				   type_definition_defs=[ F | TypeDefsDefs ] } );



% Type export section:
%
process_ast( _AST=[ F={ attribute, _Line, export_type, DeclaredTypes } | T ],
			 W=#module_info{ type_exports=TypeExports,
							 type_export_defs=TypeExportDefs } )
  when is_list( DeclaredTypes ) ->

	%io:format( " - export type declaration for ~p~n", [ DeclaredTypes ] ),

	process_ast( T, W#module_info{ type_exports= DeclaredTypes ++ TypeExports,
								   type_export_defs=[ F | TypeExportDefs ] } );



% Function export section:
%
process_ast( _AST=[ Form={ attribute, _Line, export, FunctionIds } | T ],
			 W=#module_info{ function_exports=FunExports,
							 functions=FunctionTable } ) ->

	%io:format( " - export declaration for ~p~n", [ FunctionIds ] ),

	NewFunctionTable = lists:foldl(

		fun( FunId={ Name, Arity }, FunTableAcc ) ->

			 NewFunInfo = case map_hashtable:lookupEntry( FunId,
														  FunTableAcc ) of

				 key_not_found ->

					  % New entry then:
					  #function_info{
						 name=Name,
						 arity=Arity,
						 % Implicit:
						 %definition=[],
						 %spec=undefined
						 exported=true

						};

				 % A function *might* be exported more than once:
				 { value, F } -> % F=#function_info{ exported=false } } ->
					  % Just add the form then:
					  F#function_info{ exported=true }

			end,

			map_hashtable:addEntry( FunId, NewFunInfo, FunTableAcc )

		end,

						 _Acc0=FunctionTable,
						 _List=FunctionIds ),

	process_ast( T, W#module_info{
					  function_exports=[ Form | FunExports ],
					  functions=NewFunctionTable } );


% Function definition section:
%
process_ast( _AST=[ _Form={ function, _Line, Name, Arity, Clauses } | T ],
			 W=#module_info{ functions=FunctionTable } ) ->

	%io:format( " - function definition for ~p:~p~n", [ Name, Arity ] ),

	% The non-first clauses could be checked as well:
	%
	% (when adding a function, we may not check if ever there was a pre-existing
	% one - multiple definitions will be rejected by the compiler anyway)

	FunId = { Name, Arity },

	FunInfo = case map_hashtable:lookupEntry( FunId, FunctionTable ) of

		key_not_found ->

					  % New entry then:
					  #function_info{
						 name=Name,
						 arity=Arity,
						 definition=Clauses
						 % Implicit:
						 %spec=undefined
						};

		{ value, F=#function_info{ definition=[] } } ->
					  % Just add the form then:
					  F#function_info{ definition=Clauses };

		% Here a definition was already set:
		_ ->
					  raise_error( { multiple_definition_for, FunId } )

	end,

	NewFunctionTable = map_hashtable:addEntry( _K=FunId, _V=FunInfo,
											   FunctionTable ),

	%io:format( "function ~s/~B with ~B clauses registered.~n",
	%		   [ Name, Arity, length( Clauses ) ] ),

	process_ast( T, W#module_info{ functions=NewFunctionTable }  );



% Spec attributes:
process_ast( _AST=[ Form={ attribute, _Line, spec, {
											   FunId={ FunctionName, Arity },
											   _SpecList } } | T ],
			 W=#module_info{ functions=FunctionTable } ) ->

	%io:format( " - spec definition for ~p:~p~n", [ FunctionName, Arity ] ),

	FunInfo = case map_hashtable:lookupEntry( FunId, FunctionTable ) of

		key_not_found ->

					  % New entry then:
					  #function_info{
						 name=FunctionName,
						 arity=Arity,
						 % Implicit:
						 %definition=[]
						 spec=Form
						};

		{ value, F=#function_info{ spec=undefined } } ->
					  % Just add the form then:
					  F#function_info{ spec=Form };

		% Here a spec was already set:
		_ ->
					  raise_error( { multiple_spec_for, FunId } )

	end,

	NewFunctionTable = map_hashtable:addEntry( _K=FunId, _V=FunInfo,
											   FunctionTable ),

	%io:format( "spec for function ~s/~B registered.~n",
	%		   [ FunctionName, Arity ] ),

	process_ast( T, W#module_info{ functions=NewFunctionTable } );



% Other attribute section:
%
process_ast( _AST=[ F={ attribute, _Line, AttributeName, AttributeValue }
					   | T ],
			 W=#module_info{ parse_attributes=Attributes,
							 parse_attribute_defs=AttributeDefs } ) ->

	%io:format( " - attribute definition for ~p~n", [ AttributeName ] ),

	process_ast( T, W#module_info{
				   parse_attributes=[ { AttributeName, AttributeValue }
									  | Attributes ],
				   parse_attribute_defs=[ F | AttributeDefs ] } );



% We expect the module name to be known when ending the processing:
%
process_ast( _AST=[ _F={ eof, _Line } ],
			 Infos=#module_info{ module=undefined } ) ->
	raise_error( { eof_while_no_module, Infos } );



% Form expected to be defined once, and not kept as will be added back later:
%
process_ast( _AST=[ _F={ eof, Line } ], W=#module_info{ last_line=undefined,
							   module=Module, includes=Inc } ) ->

	%io:format( " - eof declaration at ~p~n", [ Line ] ),

	% We do not want to have the filename of the currently processed module in
	% the includes:

	% Reconstructs the supposedly deduced module filename:
	ModFilename = atom_to_list( Module ) ++ ".erl",

	% Due to the removal of include duplicates, can be listed only up to once:
	NoModInc = lists:delete( ModFilename, Inc ),

	% Only "normal" exit of that function:
	W#module_info{ last_line=Line, includes=NoModInc };


% We ensure that we captured all possible forms:
%
process_ast( _AST=[ H | _T ], _Infos ) ->

	%io:format( "WARNING: unhandled form '~p' not managed.~n", [ H ] ),
	%process_ast( T, Infos );

	raise_error( { unhandled_form, H } );


process_ast( _AST=[], Infos ) ->
	raise_error( { no_eof_found, Infos } ).



% Reads specified Erlang source file (*.erl) and returns the corresponding AST.
%
% For example useful to debug a parse transform first separately from the
% compile pipe-line, relying here on the usual, convenient error management
% instead of having little informative messages like: 'undefined parse transform
% 'foobar'' as soon as a call to a non-existing module/function is made.
%
-spec erl_to_ast( file_utils:file_name() ) -> ast().
erl_to_ast( ErlSourceFilename ) ->

	case epp:parse_file( ErlSourceFilename, _Opts=[] ) of

		{ error, Error } ->
			throw( { parse_file_failed, ErlSourceFilename, Error } );

		{ ok, AST } ->
			AST

	end.



% Checks the correctness of specified module information.
%
-spec check_module_info( module_info() ) -> basic_utils:void().
check_module_info( #module_info{ module=undefined } ) ->
	raise_error( no_module_known );

check_module_info( #module_info{ module_def=undefined } ) ->
	raise_error( no_module_defined );

check_module_info( #module_info{ last_line=undefined } ) ->
	raise_error( no_last_line_found );

check_module_info( Module ) ->
	%io:format( "Checking AST.~n" ),
	check_module_parse( Module ),
	check_module_include( Module ),
	check_module_type_definition( Module ),
	check_module_export( Module ),
	check_module_functions( Module ).



% Helper to check module parsed attributes.
%
check_module_parse( #module_info{
						 parse_attributes=ParseAttributes,
						 parse_attribute_defs=ParseAttributeDefs } ) ->

	Len = length( ParseAttributes ),

	case length( ParseAttributeDefs ) of

		Len ->
			ok;

		_ ->
			raise_error( { parse_attribute_mismatch, ParseAttributes,
									  ParseAttributeDefs } )

	end.


% Helper to check module includes.
%
check_module_include( #module_info{
						 includes=Includes,
						 include_defs=IncludeDefs } ) ->

	Len = length( Includes ),

	case length( IncludeDefs ) of

		% Includes are filtered (ex: for duplicates):
		L when L < Len ->
			raise_error( { include_mismatch, Includes,
									  IncludeDefs } );

		_ ->
			ok

	end.


% Helper to check module type definitions.
%
check_module_type_definition( #module_info{
						 type_definitions=TypeDefs,
						 type_definition_defs=TypeDefsDefs } ) ->

	Len = length( TypeDefs ),

	case length( TypeDefsDefs ) of

		Len ->
			ok;

		_ ->
			raise_error( { type_definition_mismatch, TypeDefs,
									  TypeDefsDefs } )

	end.


% Helper to check module type exports.
%
check_module_export( #module_info{
						 type_exports=TypeExports,
						 type_export_defs=TypeExportDefs } ) ->

	Len = length( TypeExports ),

	case length( TypeExportDefs ) of

		% A single export attribute can export monre than one type:
		%
		L when L > Len ->
			raise_error( { type_export_mismatch, TypeExports,
									  TypeExportDefs } );

		_ ->
			ok

	end.



% Helper to check module functions.
%
check_module_functions( #module_info{ functions=Functions } ) ->

	FunInfos = map_hashtable:enumerate( Functions ),

	[ check_function( FunId, FunInfo ) || { FunId, FunInfo } <- FunInfos ].



% Nothing to check for 'spec' or 'exported':
%
check_function( FunId, _FunInfo=#function_info{ definition=[] } ) ->
	raise_error( { no_definition_found_for, FunId } );

check_function( _FunId={ Name, Arity }, _FunInfo=#function_info{
										  name=Name,
										  arity=Arity } ) ->
	% Match:
	ok;

check_function( FunId, _FunInfo=#function_info{
						 name=SecondName,
						 arity=SecondArity } ) ->
	raise_error( { definition_mismatch, FunId,
							  { SecondName, SecondArity } } ).



-spec module_info_to_string( module_info() ) -> text_utils:ustring().
module_info_to_string( #module_info{
						 module=Module,
						 module_def=ModuleDef,
						 compilation_option_defs=CompileOptDefs,
						 parse_attributes=ParseAttributes,
						 parse_attribute_defs=ParseAttributeDefs,
						 includes=Includes,
						 include_defs=IncludeDefs,
						 type_definitions=TypeDefs,
						 type_definition_defs=TypeDefsDefs,
						 type_exports=TypeExports,
						 type_export_defs=TypeExportDefs,
						 function_exports=FunctionExports,
						 functions=Functions,
						 last_line=LastLine
						} ) ->

	FunctionStrings = [ io_lib:format( "for function ~s/~B: ~s",
							[ Name, Arity, function_info_to_string( Info ) ] )
							  || { { Name, Arity }, Info } <-
									 map_hashtable:enumerate( Functions ) ],

	Infos = [

			  text_utils:format( "module: ~p~n", [ Module ] ),
			  text_utils:format( "module definition: ~p~n", [ ModuleDef ] ),

			  text_utils:format( "~B compile option definitions: ~p~n",
								 [ length( CompileOptDefs ), CompileOptDefs ] ),

			  text_utils:format( "~B parse attributes: ~p~n",
								 [ length( ParseAttributes ),
								   ParseAttributes ] ),

			  text_utils:format( "parse attribute definitions: ~p~n",
								 [ ParseAttributeDefs ] ),

			  text_utils:format( "~B actual includes: ~p~n",
								 [ length( Includes ), Includes ] ),

			  text_utils:format( "include definitions: ~p~n", [ IncludeDefs ] ),

			  text_utils:format( "~B type definitions: ~p~n",
								 [ length( TypeDefs ), TypeDefs ] ),

			  text_utils:format( "type definitions: ~p~n",
								 [ TypeDefsDefs ] ),

			  text_utils:format( "~B type exports: ~p~n",
								 [ length( TypeExports ), TypeExports ] ),

			  text_utils:format( "type export definitions: ~p~n",
								 [ TypeExportDefs ] ),

			  text_utils:format( "~B function export definitions: ~p~n",
					 [ length( FunctionExports ), FunctionExports ] ),

			  text_utils:format( "~B functions: ~s~n",
					 [ length( FunctionStrings ),
					   text_utils:strings_to_string( FunctionStrings,
													 _Bullet="   * " ) ] ),

			  text_utils:format( "line count: ~B", [ LastLine ] )

			  ],

	text_utils:format( "Information about module '~s':~n~s",
					   [ Module, text_utils:strings_to_string( Infos ) ] ).




% Used to be a simple throw, but then for parse transforms the error message was
% garbled in messages like:
%
% """
% internal error in lint_module;
% crash reason: function_clause
%
%  in function  erl_lint:'-compiler_options/1-lc$^0/1-0-'/1
%     called as erl_lint:'-compiler_options/1-lc$^0/1-0-'({
% table_type_defined_more_than_once,{line,12},foo_hashtable,bar_hashtable})
%
-spec raise_error( term() ) -> no_return().
raise_error( ErrorTerm ) ->

	%throw( ErrorTerm )
	%io:format( "~n~n*** Error:~n~p.~n", [ ErrorTerm ] ),

	% Does not add any information (just non-relevant erl_parse, epp
	% etc. state):
	%
	%erlang:exit( { ErrorTerm, erlang:get_stacktrace() } ).

	erlang:exit( ErrorTerm ).
